# === –ò–º–ø–æ—Ä—Ç—ã –∏ –±–∞–∑–æ–≤–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ ===
import asyncio
import csv
import os
import zipfile
from typing import List, Dict
import streamlit as st
from pydub import AudioSegment
from googletrans import Translator
from gtts import gTTS
from io import StringIO, BytesIO
import base64
from datetime import datetime
import pandas as pd
from collections import Counter

# === –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –∏ –ø–∞–ø–∫–∞–º ===
CSV_CACHE_FILE = "transcription_cache.csv"
LAST_SESSION_FOLDER = "sessions"
AUDIO_FOLDER = "audio_files"
os.makedirs(AUDIO_FOLDER, exist_ok=True)
os.makedirs(LAST_SESSION_FOLDER, exist_ok=True)

# === –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤ (–ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏) ===
NORMALIZATION_MAP = {
    'vinere': 'vineri'  # –∏—Å–ø—Ä–∞–≤–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
}

# === –ó–∞–º–µ–Ω–∏—Ç–µ–ª–∏ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Ä—É–º—ã–Ω—Å–∫–æ–≥–æ –≤ IPA ===
IPA_REPLACEMENTS = [
    ('ce', 'tÕ° Ée'), ('ci', 'tÕ° Éi'), ('ge', 'dÕ° íe'), ('gi', 'dÕ° íi'),
    ('ch', 'k'), ('gh', 'g'), ('ƒÉ', '…ô'), ('√¢', '…®'), ('√Æ', '…®'),
    ('»ô', ' É'), ('≈£', 'tÕ°s'), ('»õ', 'tÕ°s')
]

# === –†—É—Å—Å–∫–∞—è –ø—Ä–∏–±–ª–∏–∂—ë–Ω–Ω–∞—è —Ñ–æ–Ω–µ—Ç–∏–∫–∞ ===
RU_REPLACEMENTS = [
    ('ce', '—á–µ'), ('ci', '—á–∏'), ('ge', '–¥–∂–µ'), ('gi', '–¥–∂–∏'),
    ('ch', '–∫'), ('gh', '–≥'), ('ƒÉ', '—ç'), ('√¢', '—ã'), ('√Æ', '—ã'),
    ('»ô', '—à'), ('≈£', '—Ü'), ('»õ', '—Ü'), ('a', '–∞'), ('e', '–µ'),
    ('i', '–∏'), ('o', '–æ'), ('u', '—É'), ('b', '–±'), ('c', '–∫'),
    ('d', '–¥'), ('f', '—Ñ'), ('g', '–≥'), ('h', '—Ö'), ('j', '–∂'),
    ('k', '–∫'), ('l', '–ª'), ('m', '–º'), ('n', '–Ω'), ('p', '–ø'),
    ('q', '–∫'), ('r', '—Ä'), ('s', '—Å'), ('t', '—Ç'), ('v', '–≤'),
    ('w', '–≤'), ('x', '–∫—Å'), ('y', '–∏'), ('z', '–∑')
]

# === –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ñ–ª–∞–≥–æ–≤ –¥–ª—è —è–∑—ã–∫–æ–≤ ===
LANG_FLAGS = {
    "ru": "üá∑üá∫ –†—É—Å—Å–∫–∏–π",
    "en": "üá¨üáß –ê–Ω–≥–ª–∏–π—Å–∫–∏–π",
    "ro": "üá∑üá¥ –†—É–º—ã–Ω—Å–∫–∏–π"
}

translator = Translator()

# === –ü–µ—Ä–µ–≤–æ–¥ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ ===
async def translate_phrase(phrase: str, dest='ru') -> str:
    try:
        translation = await translator.translate(phrase, src='ro', dest=dest)
        return translation.text
    except Exception as e:
        return f"[–æ—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {e}]"

def translate_ru_to_ro(phrase: str) -> str:
    try:
        return asyncio.run(translator.translate(phrase, src='ru', dest='ro')).text
    except Exception as e:
        return f"[–æ—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {e}]"

def normalize(phrase: str) -> str:
    words = phrase.lower().split()
    return ' '.join(NORMALIZATION_MAP.get(w, w) for w in words)

def apply_replacements(phrase: str, rules: List[tuple]) -> str:
    result = phrase.lower()
    for orig, repl in rules:
        result = result.replace(orig, repl)
    return result

def speak(phrase: str, filename: str, lang='ro'):
    mp3_path = os.path.join(AUDIO_FOLDER, filename)
    if not os.path.exists(mp3_path):
        tts = gTTS(text=phrase, lang=lang)
        tts.save(mp3_path)
    return mp3_path

def load_csv_cache(csv_path: str) -> Dict[str, dict]:
    if not os.path.exists(csv_path):
        return {}
    existing_data = {}
    with open(csv_path, mode="r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            row = dict(row)
            row.setdefault('known', '‚ùå')
            row.setdefault('category', '')
            row.setdefault('date_added', '')
            row.setdefault('date_known', '')
            key = (row.get("normalized", "").strip(), row.get("lang", "").strip())
            if key:
                existing_data[key] = row
    return existing_data

def save_csv_file(data: List[dict], csv_path: str):
    with open(csv_path, mode="w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(
            f,
            fieldnames=[
                "original", "normalized", "ipa", "ru_phonetic", "translation",
                "lang", "known", "category", "date_added", "date_known"
            ]
        )
        writer.writeheader()
        writer.writerows(data)

async def process_phrases(phrases: List[str], cache: Dict[str, dict], lang='ru', study_lang_code='ro') -> List[dict]:
    results = []
    for phrase in set(phrases):
        normalized = normalize(phrase)
        cache_key = (normalized, lang)
        if cache_key in cache:
            results.append(cache[cache_key])
            continue
        result = {
            'original': phrase,
            'normalized': normalized,
            'ipa': apply_replacements(normalized, IPA_REPLACEMENTS if study_lang_code == 'ro' else []),
            'ru_phonetic': apply_replacements(normalized, RU_REPLACEMENTS if study_lang_code == 'ro' else []),
            'translation': await translate_phrase(normalized, dest=lang if lang != study_lang_code else 'ru'),
            'lang': lang,
            'known': '‚ùå',
            'category': st.session_state.get("category_input", "").strip(),
            'date_added': datetime.now().strftime('%Y-%m-%d'),
            'date_known': '',
        }
        cache[cache_key] = result
        results.append(result)
        speak(normalized, f"{normalized.replace(' ', '_')}_{study_lang_code}.mp3", lang=study_lang_code)
    return results

def make_zip_of_audio(phrases: List[str], results: List[dict], with_translation=False, lang='ru', study_lang_code='ro') -> BytesIO:
    zip_buffer = BytesIO()
    with zipfile.ZipFile(zip_buffer, "w") as zip_file:
        for row in results:
            normalized = row['normalized']
            base_name = normalized.replace(' ', '_')
            ro_file = f"{base_name}_{study_lang_code}.mp3"
            ro_path = speak(normalized, ro_file, lang=study_lang_code)
            zip_file.write(ro_path, arcname=ro_file)

            if with_translation:
                trans_text = row['translation']
                tr_file = f"{base_name}_{lang}.mp3"
                tr_path = speak(trans_text, tr_file, lang=lang)
                merged = AudioSegment.from_file(ro_path) + AudioSegment.silent(duration=500) + AudioSegment.from_file(tr_path)
                final_path = os.path.join(AUDIO_FOLDER, f"{base_name}_combo.mp3")
                merged.export(final_path, format="mp3")
                zip_file.write(final_path, arcname=f"{base_name}_combo.mp3")
    zip_buffer.seek(0)
    return zip_buffer


# === Streamlit UI ===
st.set_page_config(page_title="Romanian Transcriber", layout="wide")
st.title("üìò Transcriber & Translator")

study_lang = st.selectbox("üß† –Ø–∑—ã–∫ –∏–∑—É—á–µ–Ω–∏—è:", ["–†—É–º—ã–Ω—Å–∫–∏–π (ro)", "–ê–Ω–≥–ª–∏–π—Å–∫–∏–π (en)"], index=0)
study_lang_code = "ro" if "ro" in study_lang else "en"

session_files = [f for f in os.listdir(LAST_SESSION_FOLDER) if f.endswith(".csv")]
load_session = st.selectbox("üìÇ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–µ—Å—Å–∏—é:", ["(–Ω–µ –≤—ã–±—Ä–∞–Ω–∞)"] + session_files)

input_method = st.radio("–í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–æ—Å–æ–± –≤–≤–æ–¥–∞:", ["–í–≤–æ–¥ –≤—Ä—É—á–Ω—É—é", "–ó–∞–≥—Ä—É–∑–∫–∞ .txt —Ñ–∞–π–ª–∞"])
translation_lang = st.selectbox("–Ø–∑—ã–∫ –ø–µ—Ä–µ–≤–æ–¥–∞:", [(LANG_FLAGS['ru'], "ru"), (LANG_FLAGS['en'], "en")])
save_last_session = st.checkbox("–°–æ—Ö—Ä–∞–Ω—è—Ç—å —Ç–µ–∫—É—â—É—é —Å–µ—Å—Å–∏—é –æ—Ç–¥–µ–ª—å–Ω–æ", value=True)
append_to_current_session = st.checkbox("üìé –î–æ–±–∞–≤–∏—Ç—å –∫ —Ç–µ–∫—É—â–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π —Å–µ—Å—Å–∏–∏ (–µ—Å–ª–∏ –≤—ã–±—Ä–∞–Ω–∞)", value=True)

phrases = []

if 'manual_input' not in st.session_state:
    st.session_state['manual_input'] = ""
if 'results' not in st.session_state:
    st.session_state['results'] = []

if load_session != "(–Ω–µ –≤—ã–±—Ä–∞–Ω–∞)":
    try:
        with open(os.path.join(LAST_SESSION_FOLDER, load_session), mode="r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            st.session_state['results'] = list(reader)
        st.success(f"–°–µ—Å—Å–∏—è {load_session} –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
    except Exception as e:
        st.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–µ—Å—Å–∏–∏: {e}")

if input_method == "–í–≤–æ–¥ –≤—Ä—É—á–Ω—É—é":
    ru_input = st.text_input("‚úçÔ∏è –í–≤–µ–¥–∏—Ç–µ —Ñ—Ä–∞–∑—É (–ø–µ—Ä–µ–≤–æ–¥ –Ω–∞ —Ä—É–º—ã–Ω—Å–∫–∏–π –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω):")
    category_input = st.text_input("üè∑Ô∏è –ö–∞—Ç–µ–≥–æ—Ä–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):", key="category_input")
    if st.button("–î–æ–±–∞–≤–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥", key="add_translation"):
        try:
            ro_phrase = asyncio.run(translator.translate(ru_input, src=translation_lang[1], dest=study_lang_code)).text
            st.session_state['manual_input'] += ("\n" if st.session_state['manual_input'] else "") + ro_phrase.strip()
        except Exception as e:
            st.warning(f"[–æ—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {e}]")
    st.session_state['manual_input'] = st.text_area("üì• –í–≤–µ–¥–∏—Ç–µ —Ñ—Ä–∞–∑—ã (–ø–æ –æ–¥–Ω–æ–π –Ω–∞ —Å—Ç—Ä–æ–∫–µ):", value=st.session_state['manual_input'], height=200)
    if st.session_state['manual_input'].strip():
        phrases = [line.strip() for line in st.session_state['manual_input'].splitlines() if line.strip()]
else:
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ .txt —Ñ–∞–π–ª", type=["txt"])
    if uploaded_file:
        stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))
        phrases = [line.strip() for line in stringio if line.strip()]

if phrases and st.button("‚ñ∂Ô∏è –û–±—Ä–∞–±–æ—Ç–∞—Ç—å"):
    with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞..."):
        cache = load_csv_cache(CSV_CACHE_FILE)
        results = asyncio.run(process_phrases(phrases, cache, lang=translation_lang[1], study_lang_code=study_lang_code))
        save_csv_file(list(cache.values()), CSV_CACHE_FILE)
        if save_last_session:
            if load_session != "(–Ω–µ –≤—ã–±—Ä–∞–Ω–∞)" and append_to_current_session:
                # üîÅ –î–æ–±–∞–≤–ª—è–µ–º –∫ —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏
                existing_path = os.path.join(LAST_SESSION_FOLDER, load_session)
                merged = load_csv_cache(existing_path)
                for r in results:
                    merged[(r['normalized'], r['lang'])] = r
                save_csv_file(list(merged.values()), existing_path)
                st.session_state['results'] = list(merged.values())

                st.success(f"–°–ª–æ–≤–∞ –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ —Å–µ—Å—Å–∏—é: {load_session}")
            else:
                # üÜï –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é
                session_name = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                save_csv_file(results, os.path.join(LAST_SESSION_FOLDER, session_name))
                st.success(f"–°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è —Å–µ—Å—Å–∏—è: {session_name}")
        if not (load_session != "(–Ω–µ –≤—ã–±—Ä–∞–Ω–∞)" and append_to_current_session):        
            st.session_state['results'] = results
        
    st.success("‚úÖ –ì–æ—Ç–æ–≤–æ!")

if st.session_state['results']:
    filter_text = st.text_input("üîç –§–∏–ª—å—Ç—Ä –ø–æ —Ñ—Ä–∞–∑–µ –∏–ª–∏ –ø–µ—Ä–µ–≤–æ–¥—É:")
    filtered = [row for row in st.session_state['results'] if filter_text.lower() in row['original'].lower() or filter_text.lower() in row['translation'].lower()]

    st.download_button("üì• –°–∫–∞—á–∞—Ç—å CSV", data=open(CSV_CACHE_FILE, "rb"), file_name="results.csv")

    audio_zip = make_zip_of_audio([row['original'] for row in filtered], filtered, lang=translation_lang[1], study_lang_code=study_lang_code)
    st.download_button("üîä –°–∫–∞—á–∞—Ç—å MP3 (–∞—Ä—Ö–∏–≤)", data=audio_zip, file_name="audio_files.zip")

    st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    st.dataframe(filtered, use_container_width=True)

    st.subheader("üéß –ü—Ä–æ—Å–ª—É—à–∞—Ç—å –æ–∑–≤—É—á–∫—É:")
    if st.button("‚ñ∂Ô∏è –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ –≤—Å—ë"):
        combined = AudioSegment.empty()
        for row in filtered:
            filename = f"{row['normalized'].replace(' ', '_')}_{study_lang_code}.mp3"
            path = speak(row['normalized'], filename, lang=study_lang_code)
            if os.path.exists(path):
                combined += AudioSegment.from_file(path) + AudioSegment.silent(duration=300)
        buffer = BytesIO()
        combined.export(buffer, format="mp3")
        buffer.seek(0)
        b64 = base64.b64encode(buffer.read()).decode()
        st.markdown(f"""
            <audio autoplay controls loop>
            <source src="data:audio/mp3;base64,{b64}" type="audio/mp3">
            </audio>
        """, unsafe_allow_html=True)

    if st.checkbox("üîÅ –í–∫–ª—é—á–∏—Ç—å –¥–≤–æ–π–Ω—É—é –æ–∑–≤—É—á–∫—É (—Ñ—Ä–∞–∑–∞ + –ø–µ—Ä–µ–≤–æ–¥)"):
        combo_audio = AudioSegment.empty()
        for row in filtered:
            base = row['normalized'].replace(' ', '_')
            ro_path = speak(row['normalized'], f"{base}_{study_lang_code}.mp3", lang=study_lang_code)
            tr_path = speak(row['translation'], f"{base}_{translation_lang[1]}.mp3", lang=translation_lang[1])
            if os.path.exists(ro_path) and os.path.exists(tr_path):
                seg = AudioSegment.from_file(ro_path) + AudioSegment.silent(duration=500) + AudioSegment.from_file(tr_path)
                combo_audio += seg + AudioSegment.silent(duration=500)
        if len(combo_audio) > 0:
            combined_path = os.path.join(AUDIO_FOLDER, "all_combined.mp3")
            combo_audio.export(combined_path, format="mp3")
            st.audio(combined_path, format="audio/mp3")
            double_zip = make_zip_of_audio([row['original'] for row in filtered], filtered, with_translation=True, lang=translation_lang[1], study_lang_code=study_lang_code)
            st.download_button("üì• –°–∫–∞—á–∞—Ç—å –¥–≤–æ–π–Ω—É—é –æ–∑–≤—É—á–∫—É (zip)", data=double_zip, file_name="combo_audio.zip")
            
# === –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ñ–∏–ª—å—Ç—Ä –∏ –≤–∫–ª–∞–¥–∫–∏ ===
if st.session_state['results']:
    st.markdown("---")
    
    # üéõÔ∏è –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–µ—Ä–µ–¥ –≤–∫–ª–∞–¥–∫–∞–º–∏
    col1, col2 = st.columns([3, 2])
    with col1:
        filter_text = st.text_input("üîç –§–∏–ª—å—Ç—Ä –ø–æ —Ñ—Ä–∞–∑–µ –∏–ª–∏ –ø–µ—Ä–µ–≤–æ–¥—É:", key="filter_text")
    with col2:
        show_only_unknown = st.checkbox("üîÅ –¢–æ–ª—å–∫–æ ‚ùå –Ω–µ–≤—ã—É—á–µ–Ω–Ω—ã–µ", key="filter_unknown")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º known_map –æ–¥–∏–Ω —Ä–∞–∑
    if 'known_map' not in st.session_state:
        st.session_state['known_map'] = {}
        st.session_state['date_known_map'] = {}
        
    all_categories = sorted(set(r.get("category", "").strip() for r in st.session_state['results'] if r.get("category")))
    selected_category = st.selectbox("üìÇ –ö–∞—Ç–µ–≥–æ—Ä–∏—è:", ["(–≤—Å–µ)"] + all_categories, index=0)

    # üß† –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ —Å—Ç–∞—Ç—É—Å
    df_display = [
        r for r in st.session_state['results']
        if (not show_only_unknown or r.get("known") != '‚úÖ')
        and (selected_category == "(–≤—Å–µ)" or r.get("category", "") == selected_category)
        and (filter_text.lower() in r['original'].lower() or filter_text.lower() in r['translation'].lower())
    ]

    # === –í–∫–ª–∞–¥–∫–∏ ===
    tabs = st.tabs(["üìã –¢–∞–±–ª–∏—Ü–∞", "üß† –ö–∞—Ä—Ç–æ—á–∫–∏ (Flashcards)", "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"])

    # === –í–∫–ª–∞–¥–∫–∞ –∫–∞—Ä—Ç–æ—á–µ–∫ ===
    with tabs[1]:
        st.subheader("üß† –£—á–∏–º —Ñ—Ä–∞–∑—ã")

        for idx, row in enumerate(df_display):
            normalized_key = row['normalized']
            lang_key = row['lang']

            # –ó–∞–≥—Ä—É–∑–∏–º —Å—Ç–∞—Ç—É—Å known
            known_val = st.session_state['known_map'].get((normalized_key, lang_key), row.get('known', '‚ùå'))
            row['known'] = known_val
            date_known_val = st.session_state['date_known_map'].get((normalized_key, lang_key), row.get('date_known', ''))
            row['date_known'] = date_known_val

            # –ê–≤—Ç–æ–æ—Ç–∫—Ä—ã—Ç–∏–µ –ø–µ—Ä–≤–æ–π –Ω–µ–∑–Ω–∞–∫–æ–º–æ–π –∫–∞—Ä—Ç–æ—á–∫–∏
            auto_open = True if show_only_unknown and known_val != '‚úÖ' and idx == 0 else False

            with st.expander(f"{row['original']} ‚Üí {row['translation']}", expanded=auto_open):
                st.markdown(f"IPA: `{row.get('ipa', '')}`")
                st.markdown(f"–§–æ–Ω–µ—Ç–∏–∫–∞: `{row.get('ru_phonetic', '')}`")
                if row.get("category"):
                    st.markdown(f"üè∑Ô∏è –ö–∞—Ç–µ–≥–æ—Ä–∏—è: _{row['category']}_")

                audio_path = speak(
                    row['normalized'],
                    f"{row['normalized'].replace(' ', '_')}_{study_lang_code}.mp3",
                    lang=study_lang_code
                )
                st.audio(audio_path)

                # –¶–≤–µ—Ç–Ω–æ–π —Å—Ç–∞—Ç—É—Å
                status_color = "green" if known_val == '‚úÖ' else "red"
                st.markdown(
                    f"**–¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å:** <span style='color:{status_color}'>{known_val}</span>",
                    unsafe_allow_html=True
                )

                # –ö–Ω–æ–ø–∫–∏
                col1, col2 = st.columns(2)
                if col1.button("‚úÖ –ó–Ω–∞—é", key=f"know_{idx}"):
                    k = (normalized_key, lang_key)
                    st.session_state['known_map'][k] = '‚úÖ'
                    st.session_state['date_known_map'][k] = datetime.now().strftime('%Y-%m-%d')
                    row['known'] = '‚úÖ'
                    row['date_known'] = st.session_state['date_known_map'][k]
                if col2.button("‚ùå –ù–µ –∑–Ω–∞—é", key=f"dontknow_{idx}"):
                    st.session_state['known_map'][k] = '‚ùå'
                    st.session_state['date_known_map'][k] = ''
                    row['known'] = '‚ùå'
                    row['date_known'] = ''

        if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞—Ä—Ç–æ—á–∫–∏", key="save_cards"):
            save_csv_file(st.session_state['results'], CSV_CACHE_FILE)
            # –ï—Å–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —Å–µ—Å—Å–∏—è ‚Äî –æ–±–Ω–æ–≤–∏–º –µ—ë —Ç–æ–∂–µ
            if load_session != "(–Ω–µ –≤—ã–±—Ä–∞–Ω–∞)":
                save_csv_file(st.session_state['results'], os.path.join(LAST_SESSION_FOLDER, load_session))
            st.success("–ö–∞—Ä—Ç–æ—á–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!")

    # === –í–∫–ª–∞–¥–∫–∞ —Ç–∞–±–ª–∏—Ü—ã ===
    with tabs[0]:
        st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")

        total = len(df_display)
        known = sum(1 for row in df_display if row.get('known') == '‚úÖ')
        percent = int(100 * known / total) if total > 0 else 0
        st.markdown(f"üìà –ü—Ä–æ–≥—Ä–µ—Å—Å: **{known} –∏–∑ {total}** ({percent}%)")
        st.progress(percent)
        for row in df_display:
            row.setdefault("date_added", "")
            row.setdefault("date_known", "")
            row.setdefault("category", "")
        st.dataframe(
            pd.DataFrame(df_display)[["original", "translation", "known", "category", "date_added", "date_known"]],
            use_container_width=True
        )

        if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º", key="save_known"):
            save_csv_file(st.session_state['results'], CSV_CACHE_FILE)
            
            # –ï—Å–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —Å–µ—Å—Å–∏—è ‚Äî –æ–±–Ω–æ–≤–∏–º –µ—ë —Ç–æ–∂–µ
            if load_session != "(–Ω–µ –≤—ã–±—Ä–∞–Ω–∞)":
                save_csv_file(st.session_state['results'], os.path.join(LAST_SESSION_FOLDER, load_session))
        
            st.success("–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ!")

    with tabs[2]:
        st.subheader("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–∑—É—á–µ–Ω–∏—è")
        # üéØ –¶–µ–ª—å –Ω–∞ –¥–µ–Ω—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10)
        daily_goal = st.number_input("üéØ –¶–µ–ª—å –Ω–∞ —Å–µ–≥–æ–¥–Ω—è (—Ñ—Ä–∞–∑):", min_value=1, max_value=100, value=10, step=1)
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        today_str = datetime.now().strftime('%Y-%m-%d')
        today_known = sum(
            1 for row in st.session_state['results']
            if row.get("known") == "‚úÖ" and row.get("date_known") == today_str
        )

        # üéØ –ü—Ä–æ–≥—Ä–µ—Å—Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ü–µ–ª–∏
        percent_today = int((100 * today_known / daily_goal) if daily_goal > 0 else 0)
        st.markdown(f"üìÖ –°–µ–≥–æ–¥–Ω—è –≤—ã—É—á–µ–Ω–æ: **{today_known} –∏–∑ {daily_goal}** ({percent_today}%)")
        st.progress(percent_today)

        all_stats_categories = sorted(set(
            r.get("category", "").strip() for r in st.session_state['results'] if r.get("category")
        ))

        selected_stat_category = st.selectbox("üìÇ –§–∏–ª—å—Ç—Ä –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:", ["(–≤—Å–µ)"] + all_stats_categories, index=0)

        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ñ—Ä–∞–∑—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        filtered_results = [
            row for row in st.session_state['results']
            if selected_stat_category == "(–≤—Å–µ)" or row.get("category") == selected_stat_category
        ]
        st.code(selected_stat_category)
        st.json(filtered_results)
        # –°—á–∏—Ç–∞–µ–º –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã
        added_dates = [row.get("date_added", "") for row in filtered_results if row.get("date_added")]
        added_counts = Counter(added_dates)

        # –°—á–∏—Ç–∞–µ–º –≤—ã—É—á–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã
        known_dates = [
            row.get("date_known", "")
            for row in filtered_results
            if row.get("known") == '‚úÖ' and row.get("date_known")
        ]
        known_counts = Counter(known_dates)


        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –¥–∞—Ç—ã
        all_dates = sorted(set(added_counts.keys()) | set(known_counts.keys()))

        # –°—Ç—Ä–æ–∏–º —Ç–∞–±–ª–∏—Ü—É
        chart_df = pd.DataFrame({
            "–î–∞—Ç–∞": all_dates,
            "–î–æ–±–∞–≤–ª–µ–Ω–æ": [added_counts.get(date, 0) for date in all_dates],
            "–í—ã—É—á–µ–Ω–æ": [known_counts.get(date, 0) for date in all_dates]
        }).set_index("–î–∞—Ç–∞")

        if not chart_df.empty:
            st.bar_chart(chart_df)
        else:
            st.info("–ü–æ–∫–∞ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞.")

            
    # === –°–ª—É–∂–µ–±–Ω–∞—è –æ—Ç–ª–∞–¥–∫–∞ ===
    with st.expander("üì¶ –û—Ç–ª–∞–¥–∫–∞"):
        if df_display:
            st.code("–ü–µ—Ä–≤—ã–π –∏–∑ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö:")
            st.json(df_display[0])
        if st.session_state['results']:
            st.code("–ü–µ—Ä–≤—ã–π –∏–∑ session_state['results']:")
            st.json(st.session_state['results'][0])

