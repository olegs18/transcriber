import asyncio
import csv
import os
import zipfile
from typing import List, Dict
import streamlit as st
from pydub import AudioSegment
from googletrans import Translator
from gtts import gTTS
from io import StringIO, BytesIO
import base64
from datetime import datetime

# === –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ===
CSV_CACHE_FILE = "transcription_cache.csv"
LAST_SESSION_FOLDER = "sessions"
AUDIO_FOLDER = "audio_files"
os.makedirs(AUDIO_FOLDER, exist_ok=True)
os.makedirs(LAST_SESSION_FOLDER, exist_ok=True)

NORMALIZATION_MAP = {
    'vinere': 'vineri'
}

IPA_REPLACEMENTS = [
    ('ce', 'tÕ° Ée'), ('ci', 'tÕ° Éi'), ('ge', 'dÕ° íe'), ('gi', 'dÕ° íi'),
    ('ch', 'k'), ('gh', 'g'), ('ƒÉ', '…ô'), ('√¢', '…®'), ('√Æ', '…®'),
    ('»ô', ' É'), ('≈£', 'tÕ°s'), ('»õ', 'tÕ°s')
]

RU_REPLACEMENTS = [
    ('ce', '—á–µ'), ('ci', '—á–∏'), ('ge', '–¥–∂–µ'), ('gi', '–¥–∂–∏'),
    ('ch', '–∫'), ('gh', '–≥'), ('ƒÉ', '—ç'), ('√¢', '—ã'), ('√Æ', '—ã'),
    ('»ô', '—à'), ('≈£', '—Ü'), ('»õ', '—Ü'), ('a', '–∞'), ('e', '–µ'),
    ('i', '–∏'), ('o', '–æ'), ('u', '—É'), ('b', '–±'), ('c', '–∫'),
    ('d', '–¥'), ('f', '—Ñ'), ('g', '–≥'), ('h', '—Ö'), ('j', '–∂'),
    ('k', '–∫'), ('l', '–ª'), ('m', '–º'), ('n', '–Ω'), ('p', '–ø'),
    ('q', '–∫'), ('r', '—Ä'), ('s', '—Å'), ('t', '—Ç'), ('v', '–≤'),
    ('w', '–≤'), ('x', '–∫—Å'), ('y', '–∏'), ('z', '–∑')
]

LANG_FLAGS = {
    "ru": "üá∑üá∫ –†—É—Å—Å–∫–∏–π",
    "en": "üá¨üáß –ê–Ω–≥–ª–∏–π—Å–∫–∏–π",
    "ro": "üá∑üá¥ –†—É–º—ã–Ω—Å–∫–∏–π"
}

translator = Translator()

async def translate_phrase(phrase: str, dest='ru') -> str:
    try:
        translation = await translator.translate(phrase, src='ro', dest=dest)
        return translation.text
    except Exception as e:
        return f"[–æ—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {e}]"

def translate_ru_to_ro(phrase: str) -> str:
    try:
        return asyncio.run(translator.translate(phrase, src='ru', dest='ro')).text
    except Exception as e:
        return f"[–æ—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {e}]"

def normalize(phrase: str) -> str:
    words = phrase.lower().split()
    return ' '.join(NORMALIZATION_MAP.get(w, w) for w in words)

def apply_replacements(phrase: str, rules: List[tuple]) -> str:
    result = phrase.lower()
    for orig, repl in rules:
        result = result.replace(orig, repl)
    return result

def speak(phrase: str, filename: str, lang='ro'):
    mp3_path = os.path.join(AUDIO_FOLDER, filename)
    if not os.path.exists(mp3_path):
        tts = gTTS(text=phrase, lang=lang)
        tts.save(mp3_path)
    return mp3_path

def load_csv_cache(csv_path: str) -> Dict[str, dict]:
    if not os.path.exists(csv_path):
        return {}
    existing_data = {}
    with open(csv_path, mode="r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            key = (row.get("normalized", "").strip(), row.get("lang", "").strip())
            if key:
                existing_data[key] = row
    return existing_data

def save_csv_file(data: List[dict], csv_path: str):
    with open(csv_path, mode="w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=["original", "normalized", "ipa", "ru_phonetic", "translation", "lang"])
        writer.writeheader()
        writer.writerows(data)

async def process_phrases(phrases: List[str], cache: Dict[str, dict], lang='ru', study_lang_code='ro') -> List[dict]:
    results = []
    for phrase in set(phrases):
        normalized = normalize(phrase)
        cache_key = (normalized, lang)
        if cache_key in cache:
            results.append(cache[cache_key])
            continue
        result = {
            'original': phrase,
            'normalized': normalized,
            'ipa': apply_replacements(normalized, IPA_REPLACEMENTS if study_lang_code == 'ro' else []),
            'ru_phonetic': apply_replacements(normalized, RU_REPLACEMENTS if study_lang_code == 'ro' else []),
            'translation': await translate_phrase(normalized, dest=lang if lang != study_lang_code else 'ru'),
            'lang': lang
        }
        cache[cache_key] = result
        results.append(result)
        speak(normalized, f"{normalized.replace(' ', '_')}_{study_lang_code}.mp3", lang=study_lang_code)
    return results

def make_zip_of_audio(phrases: List[str], results: List[dict], with_translation=False, lang='ru', study_lang_code='ro') -> BytesIO:
    zip_buffer = BytesIO()
    with zipfile.ZipFile(zip_buffer, "w") as zip_file:
        for row in results:
            normalized = row['normalized']
            base_name = normalized.replace(' ', '_')
            ro_file = f"{base_name}_{study_lang_code}.mp3"
            ro_path = speak(normalized, ro_file, lang=study_lang_code)
            zip_file.write(ro_path, arcname=ro_file)

            if with_translation:
                trans_text = row['translation']
                tr_file = f"{base_name}_{lang}.mp3"
                tr_path = speak(trans_text, tr_file, lang=lang)

                merged = AudioSegment.from_file(ro_path) + AudioSegment.silent(duration=500) + AudioSegment.from_file(tr_path)
                final_path = os.path.join(AUDIO_FOLDER, f"{base_name}_combo.mp3")
                merged.export(final_path, format="mp3")

                zip_file.write(final_path, arcname=f"{base_name}_combo.mp3")
    zip_buffer.seek(0)
    return zip_buffer

# === Streamlit UI ===
st.set_page_config(page_title="Romanian Transcriber", layout="wide")
st.title("üìò Transcriber & Translator")

study_lang = st.selectbox("üß† –Ø–∑—ã–∫ –∏–∑—É—á–µ–Ω–∏—è:", ["–†—É–º—ã–Ω—Å–∫–∏–π (ro)", "–ê–Ω–≥–ª–∏–π—Å–∫–∏–π (en)"], index=0)
study_lang_code = "ro" if "ro" in study_lang else "en"

session_files = [f for f in os.listdir(LAST_SESSION_FOLDER) if f.endswith(".csv")]
load_session = st.selectbox("üìÇ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–µ—Å—Å–∏—é:", ["(–Ω–µ –≤—ã–±—Ä–∞–Ω–∞)"] + session_files)

input_method = st.radio("–í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–æ—Å–æ–± –≤–≤–æ–¥–∞:", ["–í–≤–æ–¥ –≤—Ä—É—á–Ω—É—é", "–ó–∞–≥—Ä—É–∑–∫–∞ .txt —Ñ–∞–π–ª–∞"])
translation_lang = st.selectbox("–Ø–∑—ã–∫ –ø–µ—Ä–µ–≤–æ–¥–∞:", [(LANG_FLAGS['ru'], "ru"), (LANG_FLAGS['en'], "en")])
save_last_session = st.checkbox("–°–æ—Ö—Ä–∞–Ω—è—Ç—å —Ç–µ–∫—É—â—É—é —Å–µ—Å—Å–∏—é –æ—Ç–¥–µ–ª—å–Ω–æ", value=True)
phrases = []

if 'manual_input' not in st.session_state:
    st.session_state['manual_input'] = ""
if 'results' not in st.session_state:
    st.session_state['results'] = []

if load_session != "(–Ω–µ –≤—ã–±—Ä–∞–Ω–∞)":
    try:
        with open(os.path.join(LAST_SESSION_FOLDER, load_session), mode="r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            st.session_state['results'] = list(reader)
        st.success(f"–°–µ—Å—Å–∏—è {load_session} –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
    except Exception as e:
        st.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–µ—Å—Å–∏–∏: {e}")

if input_method == "–í–≤–æ–¥ –≤—Ä—É—á–Ω—É—é":
    ru_input = st.text_input("‚úçÔ∏è –í–≤–µ–¥–∏—Ç–µ —Ñ—Ä–∞–∑—É (–ø–µ—Ä–µ–≤–æ–¥ –Ω–∞ —Ä—É–º—ã–Ω—Å–∫–∏–π –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω):")
    if st.button("–î–æ–±–∞–≤–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥", key="add_translation"):
        try:
            ro_phrase = asyncio.run(translator.translate(ru_input, src=translation_lang[1], dest='ro')).text
            st.session_state['manual_input'] += ("\n" if st.session_state['manual_input'] else "") + ro_phrase.strip()
        except Exception as e:
            st.warning(f"[–æ—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {e}]")
    st.session_state['manual_input'] = st.text_area("üì• –í–≤–µ–¥–∏—Ç–µ —Ñ—Ä–∞–∑—ã (–ø–æ –æ–¥–Ω–æ–π –Ω–∞ —Å—Ç—Ä–æ–∫–µ):", value=st.session_state['manual_input'], height=200)
    if st.session_state['manual_input'].strip():
        phrases = [line.strip() for line in st.session_state['manual_input'].splitlines() if line.strip()]
else:
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ .txt —Ñ–∞–π–ª", type=["txt"])
    if uploaded_file:
        stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))
        phrases = [line.strip() for line in stringio if line.strip()]

if phrases and st.button("‚ñ∂Ô∏è –û–±—Ä–∞–±–æ—Ç–∞—Ç—å"):
    with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞..."):
        cache = load_csv_cache(CSV_CACHE_FILE)
        results = asyncio.run(process_phrases(phrases, cache, lang=translation_lang[1], study_lang_code=study_lang_code))
        save_csv_file(list(cache.values()), CSV_CACHE_FILE)
        if save_last_session:
            session_name = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            save_csv_file(results, os.path.join(LAST_SESSION_FOLDER, session_name))
        st.session_state['results'] = results
    st.success("‚úÖ –ì–æ—Ç–æ–≤–æ!")

if st.session_state['results']:
    filter_text = st.text_input("üîç –§–∏–ª—å—Ç—Ä –ø–æ —Ñ—Ä–∞–∑–µ –∏–ª–∏ –ø–µ—Ä–µ–≤–æ–¥—É:")
    filtered = [row for row in st.session_state['results'] if filter_text.lower() in row['original'].lower() or filter_text.lower() in row['translation'].lower()]

    st.download_button("üì• –°–∫–∞—á–∞—Ç—å CSV", data=open(CSV_CACHE_FILE, "rb"), file_name="results.csv")

    audio_zip = make_zip_of_audio([row['original'] for row in filtered], filtered, lang=translation_lang[1], study_lang_code=study_lang_code)
    st.download_button("üîä –°–∫–∞—á–∞—Ç—å MP3 (–∞—Ä—Ö–∏–≤)", data=audio_zip, file_name="audio_files.zip")

    st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    st.dataframe(filtered, use_container_width=True)

    st.subheader("üéß –ü—Ä–æ—Å–ª—É—à–∞—Ç—å –æ–∑–≤—É—á–∫—É:")
    if st.button("‚ñ∂Ô∏è –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ –≤—Å—ë"):
        combined = AudioSegment.empty()
        for row in filtered:
            filename = f"{row['normalized'].replace(' ', '_')}_{study_lang_code}.mp3"
            path = speak(row['normalized'], filename, lang=study_lang_code)
            if os.path.exists(path):
                combined += AudioSegment.from_file(path) + AudioSegment.silent(duration=300)
        buffer = BytesIO()
        combined.export(buffer, format="mp3")
        buffer.seek(0)
        b64 = base64.b64encode(buffer.read()).decode()
        st.markdown(f"""
            <audio autoplay controls loop>
            <source src="data:audio/mp3;base64,{b64}" type="audio/mp3">
            </audio>
        """, unsafe_allow_html=True)

    if st.checkbox("üîÅ –í–∫–ª—é—á–∏—Ç—å –¥–≤–æ–π–Ω—É—é –æ–∑–≤—É—á–∫—É (—Ñ—Ä–∞–∑–∞ + –ø–µ—Ä–µ–≤–æ–¥)"):
        combo_audio = AudioSegment.empty()
        for row in filtered:
            base = row['normalized'].replace(' ', '_')
            ro_path = speak(row['normalized'], f"{base}_{study_lang_code}.mp3", lang=study_lang_code)
            tr_path = speak(row['translation'], f"{base}_{translation_lang[1]}.mp3", lang=translation_lang[1])
            if os.path.exists(ro_path) and os.path.exists(tr_path):
                seg = AudioSegment.from_file(ro_path) + AudioSegment.silent(duration=500) + AudioSegment.from_file(tr_path)
                combo_audio += seg + AudioSegment.silent(duration=500)
        if len(combo_audio) > 0:
            combined_path = os.path.join(AUDIO_FOLDER, "all_combined.mp3")
            combo_audio.export(combined_path, format="mp3")
            st.audio(combined_path, format="audio/mp3")
            double_zip = make_zip_of_audio([row['original'] for row in filtered], filtered, with_translation=True, lang=translation_lang[1], study_lang_code=study_lang_code)
            st.download_button("üì• –°–∫–∞—á–∞—Ç—å –¥–≤–æ–π–Ω—É—é –æ–∑–≤—É—á–∫—É (zip)", data=double_zip, file_name="combo_audio.zip")
